{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First Regression with Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPraouhYmIVyAJGhWT4rl5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VMBoehm/N3ASProject_Annie/blob/main/First_Regression_with_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba4e0yulEKMw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "SO53T6AvEaok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Set fixed random number seed\n",
        "  torch.manual_seed(42)\n",
        "  \n",
        "  # Load Boston dataset\n",
        "  # TASK: what are the X and y values in this dataset?\n",
        "  X, y = load_boston(return_X_y=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeDaiLscFGzx",
        "outputId": "ab6a4dae-ee10-471c-9d63-1362dfc6e78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK: What is a class is python? What's it used for? How does inheritance work in python?\n",
        "# TASK: Find out what StandardScaler does. \n",
        "class BostonDataset(torch.utils.data.Dataset):\n",
        "  '''\n",
        "  Prepare the Boston dataset for regression\n",
        "  '''\n",
        "\n",
        "  def __init__(self, X, y, scale_data=True):\n",
        "    if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
        "      # Apply scaling if necessary\n",
        "      if scale_data:\n",
        "          X = StandardScaler().fit_transform(X)\n",
        "      self.X = torch.from_numpy(X)\n",
        "      self.y = torch.from_numpy(y)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.X)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "      return self.X[i], self.y[i]"
      ],
      "metadata": {
        "id": "rIarM2UWEbpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  '''\n",
        "    Multilayer Perceptron for regression.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # TASK: how many parameters does this network have?\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(13, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, 32),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(32, 1)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "      Forward pass\n",
        "    '''\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "UtSRIGMOE2s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Boston dataset\n",
        "dataset = BostonDataset(X, y)\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "id": "45JDMNE0FAH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the MLP\n",
        "mlp = MLP()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "# TASK: what is L1 loss? what other loss could we use?\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "_KcWPhtXFptR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the training loop\n",
        "for epoch in range(0, 5): # 5 epochs at maximum\n",
        "  \n",
        "  # Print epoch\n",
        "  print(f'Starting epoch {epoch+1}')\n",
        "  \n",
        "  # Set current loss value\n",
        "  current_loss = 0.0\n",
        "  \n",
        "  # Iterate over the DataLoader for training data\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    \n",
        "    # Get and prepare inputs\n",
        "    inputs, targets = data\n",
        "    inputs, targets = inputs.float(), targets.float()\n",
        "    targets = targets.reshape((targets.shape[0], 1))\n",
        "    \n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Perform forward pass\n",
        "    outputs = mlp(inputs)\n",
        "    \n",
        "    # Compute loss\n",
        "    loss = loss_function(outputs, targets)\n",
        "    \n",
        "    # Perform backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Perform optimization\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Print statistics\n",
        "    current_loss += loss.item()\n",
        "    if i % 10 == 0:\n",
        "        print('Loss after mini-batch %5d: %.3f' %\n",
        "              (i + 1, current_loss / 500))\n",
        "        current_loss = 0.0\n",
        "\n",
        "# Process is complete.\n",
        "print('Training process has finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WwWrz3NGGN-",
        "outputId": "a256ed24-8b82-467e-b8d5-1855d3f13538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Loss after mini-batch     1: 0.043\n",
            "Loss after mini-batch    11: 0.426\n",
            "Loss after mini-batch    21: 0.442\n",
            "Loss after mini-batch    31: 0.461\n",
            "Loss after mini-batch    41: 0.452\n",
            "Loss after mini-batch    51: 0.472\n",
            "Starting epoch 2\n",
            "Loss after mini-batch     1: 0.047\n",
            "Loss after mini-batch    11: 0.432\n",
            "Loss after mini-batch    21: 0.450\n",
            "Loss after mini-batch    31: 0.434\n",
            "Loss after mini-batch    41: 0.485\n",
            "Loss after mini-batch    51: 0.434\n",
            "Starting epoch 3\n",
            "Loss after mini-batch     1: 0.049\n",
            "Loss after mini-batch    11: 0.458\n",
            "Loss after mini-batch    21: 0.435\n",
            "Loss after mini-batch    31: 0.423\n",
            "Loss after mini-batch    41: 0.417\n",
            "Loss after mini-batch    51: 0.480\n",
            "Starting epoch 4\n",
            "Loss after mini-batch     1: 0.051\n",
            "Loss after mini-batch    11: 0.436\n",
            "Loss after mini-batch    21: 0.417\n",
            "Loss after mini-batch    31: 0.452\n",
            "Loss after mini-batch    41: 0.447\n",
            "Loss after mini-batch    51: 0.438\n",
            "Starting epoch 5\n",
            "Loss after mini-batch     1: 0.043\n",
            "Loss after mini-batch    11: 0.442\n",
            "Loss after mini-batch    21: 0.427\n",
            "Loss after mini-batch    31: 0.428\n",
            "Loss after mini-batch    41: 0.424\n",
            "Loss after mini-batch    51: 0.451\n",
            "Training process has finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK: how well does this model do? What happens when you change the network architecture? (try different modifications, e.g.: more layers/less layers; wider network; other activation functions). \n",
        "# What happens when you change the loss function?"
      ],
      "metadata": {
        "id": "JnRFzTa_GSOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}